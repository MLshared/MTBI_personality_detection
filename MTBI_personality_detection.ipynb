{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import svm\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "    from nltk.corpus import stopwords \n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "    \n",
    "    dict_lookup = {'I':0, 'E':1, 'N':0, 'S':1, \n",
    "                   'F':0, 'T':1, 'J':0, 'P':1}\n",
    "    dict_lookup_reverse = [{0:'I', 1:'E'}, {0:'N', 1:'S'},\n",
    "                           {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "    ar=['I','N','F','J']\n",
    "    Y_preddlog=[[]]\n",
    "    Y_preddknn=[[]]\n",
    "    Y_preddsvm=[[]]\n",
    "    #To remove these words if any present in the i/p.\n",
    "    mbti_words = ['INFJ', 'ENTP', 'INTP', 'INTJ',\n",
    "                  'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "                  'ISFP', 'ISTP', 'ISFJ', 'ISTJ',\n",
    "                  'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "    mbti_words = [x.lower() for x in mbti_words]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    \n",
    "    #To remove the stop words like the,a,an,in\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    def to_vector(personality):\n",
    "        # transform mbti to binary vector\n",
    "        return [dict_lookup[l] for l in personality]\n",
    "    \n",
    "    def to_mbti(personality):\n",
    "        s = \"\"\n",
    "        for i, l in enumerate(personality):\n",
    "            s += dict_lookup_reverse[i][l]\n",
    "        return s\n",
    "    \n",
    "    def data_refine(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "    \n",
    "        personality = []\n",
    "        processed_posts = []\n",
    "        len_data = len(data)\n",
    "        i=0\n",
    "        \n",
    "        for row in data.iterrows():\n",
    "            i+=1\n",
    "            if (i % 500 == 0 or i == 1 or i == len_data):\n",
    "                print(\"%s of %s rows\" % (i, len_data))\n",
    "            #To remove all the unwanted strings(eg.https,site names etc)\n",
    "            posts = row[1].posts\n",
    "            temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "            temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "            temp = re.sub(' +', ' ', temp).lower()\n",
    "            if remove_stop_words:\n",
    "                temp = \" \".join([lemmatiser.lemmatize(w) \n",
    "                         for w in temp.split(' ') if w not in stop_words])\n",
    "            else:\n",
    "                temp = \" \".join([lemmatiser.lemmatize(w) \n",
    "                        for w in temp.split(' ')])\n",
    "                \n",
    "            #To remove the mbti words in the i/p.\n",
    "            if remove_mbti_profiles:\n",
    "                for t in mbti_words:\n",
    "                    temp = temp.replace(t,\"\")\n",
    "    \n",
    "            type_labelized = to_vector(row[1].type)\n",
    "            personality.append(type_labelized)\n",
    "            processed_posts.append(temp)\n",
    "    \n",
    "        processed_posts = np.array(processed_posts)\n",
    "        personality = np.array(personality)\n",
    "        return processed_posts, personality\n",
    "    \n",
    "    data=pd.read_csv(\"mbti.csv\")\n",
    "    data['I']=data['type'].apply(lambda x:0 if x[0]=='I' else 1)\n",
    "    data['N']=data['type'].apply(lambda x:0 if x[1]=='N' else 1)\n",
    "    data['F']=data['type'].apply(lambda x:0 if x[2]=='F' else 1)\n",
    "    data['J']=data['type'].apply(lambda x:0 if x[3]=='J' else 1)\n",
    "    \n",
    "    #Processing the data to correct format to work with\n",
    "    processed_posts, personality  = data_refine(data)\n",
    "    \n",
    "    \n",
    "    # Section to assign a unique float number to the words\n",
    "    # according to the tfidf vectorizer method\n",
    "    \n",
    "    # To get the words occuring 10%-70% of the posts\n",
    "    vector = CountVectorizer(analyzer=\"word\",  \n",
    "                                 max_features=1500, \n",
    "                                 tokenizer=None,    \n",
    "                                 preprocessor=None, \n",
    "                                 stop_words=None,  \n",
    "                                 max_df=0.7,\n",
    "                                 min_df=0.1)\n",
    "    print(\"Finished the CountVectorizer\")\n",
    "    X_cnt = vector.fit_transform(processed_posts)\n",
    "    \n",
    "    tfid_vectorizer = TfidfTransformer()\n",
    "    \n",
    "    # Learn the idf vector (fit) and transform a \n",
    "    # count matrix to a tf-idf representation\n",
    "    X_tfidf =  tfid_vectorizer.fit_transform(X_cnt).toarray()\n",
    "    \n",
    "    type_indicators = [\"Introversion (I) / Extroversion (E)\",\n",
    "                       \"Intuition (N)/Sensing (S)\", \n",
    "                       \"Feeling (F)/Thinking (T)\", \n",
    "                       \"Judging (J)/Perceiving (P)\" ]\n",
    "    X = X_tfidf\n",
    "    print(\"Xgboost:\")\n",
    "    for l in range(len(type_indicators)):\n",
    "        print(\"%s ...\" % (type_indicators[l]))\n",
    "        \n",
    "        Y = personality[:,l]\n",
    "    \n",
    "        seed = 7\n",
    "        test_size = 0.33\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                          test_size=test_size, random_state=seed)\n",
    "    \n",
    "        model = XGBClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        # evaluate predictions\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], \n",
    "                                         accuracy * 100.0))\n",
    "    print(\"SVM:\")\n",
    "    for i in range(4):\n",
    "        X = X_tfidf\n",
    "        y = data[ar[i]].values\n",
    "        \n",
    "        XX_train,XX_test,yy_train,yy_test=train_test_split(X,y,\n",
    "                                           test_size = 0.33, random_state=7)\n",
    "        \n",
    "        sv = svm.SVC(gamma=\"auto\")  \n",
    "        print(\"%s ...\" % (type_indicators[i]))\n",
    "        sv.fit(XX_train, yy_train)\n",
    "        Y_preddsvm.insert(i,sv.predict(XX_test).tolist())\n",
    "        acc_logg = round(sv.score(XX_train, yy_train) * 100, 2)\n",
    "        print(\"Accuracy:\",end='')\n",
    "        print(round(acc_logg,2,), \"%\")   \n",
    "    print(\"------------------------------------------------\\nLog:\")\n",
    "    for i in range(4):\n",
    "        X = X_tfidf\n",
    "        y = data[ar[i]].values\n",
    "        \n",
    "        XX_train,XX_test,yy_train,yy_test=train_test_split(X,y,\n",
    "                                    test_size = 0.2, random_state=7)\n",
    "        \n",
    "        logregg = LogisticRegression(C=0.09,solver='liblinear')\n",
    "        print(\"%s ...\" % (type_indicators[i]))\n",
    "        logregg.fit(XX_train, yy_train)         \n",
    "        Y_preddlog.insert(i,logregg.predict(XX_test).tolist())\n",
    "        print(\"Accuracy:\",end='')\n",
    "        acc_logg = round(logregg.score(XX_train, yy_train) * 100, 2)\n",
    "        print(round(acc_logg,2,), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
